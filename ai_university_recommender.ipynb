{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdf5Wrq38j022Qx9/oM12l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajShah3006/university-recommender-ai/blob/main/ai_university_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cad82c67"
      },
      "source": [
        "!pip install -q google-generativeai"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507741af"
      },
      "source": [
        "# This is a basic example of how you could structure the chatbot logic.\n",
        "# You would need to expand on this to handle different user inputs and generate\n",
        "# responses based on the desired outputs outlined in the markdown cells.\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Assuming GOOGLE_API_KEY is already set up in Colab secrets\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Initialize the Gemini API\n",
        "model = genai.GenerativeModel('models/gemini-2.5-flash-preview-05-20')\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "def get_user_information():\n",
        "  \"\"\"Collects information from the user.\"\"\"\n",
        "  user_data = {}\n",
        "  user_data['subjects'] = input(\"What subjects are you taking currently? \")\n",
        "  user_data['intrests'] = input(\"What are your intrests, some activity that you love to put effort into or you would like to be doing in 4 years? \")\n",
        "  user_data['overall_average'] = input(\"What is your overall average? \")\n",
        "  user_data['grade'] = input(\"What grade are you in? \")\n",
        "  user_data['location'] = input(\"Where are you located? \")\n",
        "  return user_data\n",
        "\n",
        "def generate_chatbot_response(user_data):\n",
        "  \"\"\"Generates a chatbot response based on user data.\"\"\"\n",
        "  prompt = f\"\"\"Based on the following student information:\n",
        "Subjects: {user_data['subjects']}\n",
        "Intrests: {user_data['intrests']}\n",
        "Overall Average: {user_data['overall_average']}\n",
        "Grade: {user_data['grade']}\n",
        "\n",
        "Please provide some relevant information, such as:\n",
        "- What program is recomended\n",
        "- A ranking of all the universities for that specific program, also:\n",
        "  - What are the prerequisites\n",
        "  - Last few years admission average\n",
        "  - How far the university is located\n",
        "- Recommendations (courses to pursue in highschool, projects to complete for your university application)\n",
        "\n",
        "Be specific and tailor the response to the student's input. Only give information for universities in Ontario.\n",
        "\"\"\"\n",
        "  response = chat.send_message(prompt)\n",
        "  return response.text\n",
        "\n",
        "# Start the chat\n",
        "print(\"Hello! I'm a student assistant chatbot. I can help you with information related to your studies.\")\n",
        "\n",
        "# Get user information\n",
        "student_info = get_user_information()\n",
        "\n",
        "# Generate and display chatbot response\n",
        "bot_response = generate_chatbot_response(student_info)\n",
        "print(\"\\nChatbot Response:\")\n",
        "print(bot_response)\n",
        "\n",
        "print(\"\\nChat session ended.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acaf93bd",
        "outputId": "aa33cf51-b412-4fa8-eceb-06f959095c2c"
      },
      "source": [
        "# Test the scrape_university_info function with a sample URL\n",
        "test_url = \"https://www.ouinfo.ca/programs\"  # Using the new URL provided by the user\n",
        "scraped_data = scrape_university_info(test_url)\n",
        "\n",
        "if scraped_data:\n",
        "    print(\"Scraped Data:\")\n",
        "    print(scraped_data)\n",
        "else:\n",
        "    print(\"Scraping did not return data (expected with placeholder selectors).\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped Data:\n",
            "{'program': 'Agriculture, Food, Forestry, Resource Management, Vet Sciences'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba0b4138"
      },
      "source": [
        "# Task\n",
        "Integrate web scraping into the chatbot to pull information from provided links."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71635a4d"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install libraries like `requests` to fetch web page content and `BeautifulSoup` to parse HTML.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06db8b7c"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires installing the `requests` and `beautifulsoup4` libraries. I will use the `pip install` command within a code block to achieve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ace7f060"
      },
      "source": [
        "!pip install -q requests beautifulsoup4"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ade7f0f"
      },
      "source": [
        "## Create a function to scrape data\n",
        "\n",
        "### Subtask:\n",
        "Develop a function that takes a URL as input, fetches the content, and extracts the desired information using the scraping library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8701294c"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function to scrape university information from a given URL using requests and BeautifulSoup, extracting relevant details like program information, prerequisites, admission averages, and location with error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e80b61a"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_university_info(url):\n",
        "  \"\"\"\n",
        "  Scrapes university information from a given URL.\n",
        "\n",
        "  Args:\n",
        "    url: https://www.ouinfo.ca/\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the extracted university information, or None if\n",
        "    scraping fails or no information is found.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Initialize a dictionary to store the extracted information\n",
        "    university_data = {}\n",
        "\n",
        "    # *** IMPORTANT ***\n",
        "    # The following selectors are placeholders. You will need to inspect the\n",
        "    # HTML structure of the specific university websites you want to scrape\n",
        "    # and replace these with the actual CSS selectors or other methods to\n",
        "    # locate the desired information.\n",
        "\n",
        "    # Example placeholder selectors:\n",
        "    program_element = soup.select_one('h2.result-heading')\n",
        "    prerequisites_element = soup.select_one('.prerequisites-section')\n",
        "    admissions_element = soup.select_one('.admissions-average')\n",
        "    location_element = soup.select_one('.university-location')\n",
        "\n",
        "    if program_element:\n",
        "      university_data['program'] = program_element.get_text(strip=True)\n",
        "    if prerequisites_element:\n",
        "      university_data['prerequisites'] = prerequisites_element.get_text(strip=True)\n",
        "    if admissions_element:\n",
        "      university_data['admission_average'] = admissions_element.get_text(strip=True)\n",
        "    if location_element:\n",
        "      university_data['location'] = location_element.get_text(strip=True)\n",
        "\n",
        "    if university_data:\n",
        "      return university_data\n",
        "    else:\n",
        "      print(f\"No relevant information found on {url}\")\n",
        "      return None\n",
        "\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching URL {url}: {e}\")\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during scraping {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Example usage (will not return meaningful data without correct selectors)\n",
        "# test_url = \"https://www.exampleuniversity.com/program/details\"\n",
        "# university_info = scrape_university_info(test_url)\n",
        "# if university_info:\n",
        "#     print(university_info)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4284b33"
      },
      "source": [
        "## Integrate scraping into the chatbot\n",
        "\n",
        "### Subtask:\n",
        "Modify the chatbot's `generate_chatbot_response` function to call the scraping function with provided links and include the scraped data in the prompt sent to the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "606d8485"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `generate_chatbot_response` function to accept a list of URLs and include the scraped data in the prompt.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3b4c7b25"
      },
      "source": [
        "def generate_chatbot_response(user_data, university_urls):\n",
        "  \"\"\"Generates a chatbot response based on user data and scraped university info.\"\"\"\n",
        "  prompt = f\"\"\"Based on the following student information:\n",
        "Subjects: {user_data['subjects']}\n",
        "Intrests: {user_data['intrests']}\n",
        "Overall Average: {user_data['overall_average']}\n",
        "Grade: {user_data['grade']}\n",
        "\n",
        "\"\"\"\n",
        "  for url in university_urls:\n",
        "    scraped_data = scrape_university_info(url)\n",
        "    if scraped_data:\n",
        "      prompt += f\"\"\"\\nInformation scraped from {url}:\\n\"\"\"\n",
        "      for key, value in scraped_data.items():\n",
        "        prompt += f\"{key.replace('_', ' ').title()}: {value}\\n\"\n",
        "    else:\n",
        "      prompt += f\"\"\"\\nCould not retrieve information from {url}\\n\"\"\"\n",
        "\n",
        "  prompt += \"\"\"\n",
        "Please provide some relevant information, such as:\n",
        "- What program is recomended\n",
        "- A ranking of all the universities for that specific program, also:\n",
        "  - What are the prerequisites\n",
        "  - Last few years admission average\n",
        "  - How far the university is located\n",
        "- Recommendations (courses to pursue in highschool, projects to complete for your university application)\n",
        "\n",
        "Be specific and tailor the response to the student's input. Only give information for universities in Ontario.\n",
        "\"\"\"\n",
        "  response = chat.send_message(prompt)\n",
        "  return response.text"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b41c21e"
      },
      "source": [
        "## Handle potential errors\n",
        "\n",
        "### Subtask:\n",
        "Implement error handling for cases where scraping fails (e.g., invalid URL, website structure changes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccb17137"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the existing `scrape_university_info` function to ensure it includes robust error handling for potential issues like invalid URLs, network errors, and changes in website structure that might cause scraping to fail. Ensure that the function returns `None` or a specific error indicator when scraping fails, so the calling function (`generate_chatbot_response`) can handle the failure gracefully.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93f81cb5"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_university_info(url):\n",
        "  \"\"\"\n",
        "  Scrapes university information from a given URL with robust error handling.\n",
        "\n",
        "  Args:\n",
        "    url: https://www.ouinfo.ca/\n",
        "\n",
        "  Returns:\n",
        "    A dictionary containing the extracted university information, or None if\n",
        "    scraping fails or no information is found.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = requests.get(url, timeout=10)  # Add a timeout for the request\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Initialize a dictionary to store the extracted information\n",
        "    university_data = {}\n",
        "\n",
        "    # *** IMPORTANT ***\n",
        "    # Replace the following selectors with the actual CSS selectors you found\n",
        "    # by inspecting the HTML of the target university websites.\n",
        "\n",
        "    # Example placeholder selectors (REPLACE THESE):\n",
        "    program_element = soup.select_one('h2.result-heading') # Replace with actual program title selector\n",
        "    prerequisites_element = soup.select_one('.prerequisites-section') # Replace with actual prerequisites selector\n",
        "    admissions_element = soup.select_one('.admissions-average') # Replace with actual admissions average selector\n",
        "    location_element = soup.select_one('.university-location') # Replace with actual location selector\n",
        "\n",
        "    if program_element:\n",
        "      university_data['program'] = program_element.get_text(strip=True)\n",
        "    if prerequisites_element:\n",
        "      university_data['prerequisites'] = prerequisites_element.get_text(strip=True)\n",
        "    if admissions_element:\n",
        "      university_data['admission_average'] = admissions_element.get_text(strip=True)\n",
        "    if location_element:\n",
        "      university_data['location'] = location_element.get_text(strip=True)\n",
        "\n",
        "    if university_data:\n",
        "      return university_data\n",
        "    else:\n",
        "      print(f\"No relevant information found on {url}\")\n",
        "      return None\n",
        "\n",
        "  except requests.exceptions.Timeout:\n",
        "    print(f\"Request timed out for URL: {url}\")\n",
        "    return None\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching URL {url}: {e}\")\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    # Catching potential errors during parsing or data extraction\n",
        "    print(f\"An error occurred during scraping or parsing {url}: {e}\")\n",
        "    return None"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82a33a3e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The necessary libraries (`requests` and `beautifulsoup4`) for web scraping were successfully installed.\n",
        "*   A Python function `scrape_university_info` was created to fetch and parse HTML content from a given URL, with placeholder selectors for extracting specific university information.\n",
        "*   The chatbot's `generate_chatbot_response` function was modified to iterate through a list of provided URLs, call the `scrape_university_info` function for each, and include the scraped data (or a failure message) in the prompt sent to the generative model.\n",
        "*   Robust error handling was implemented in the `scrape_university_info` function to catch potential issues like request timeouts, general request errors, and exceptions during HTML parsing, ensuring the function returns `None` upon failure.\n",
        "*   The integration confirmed that `generate_chatbot_response` correctly handles the `None` return value from `scrape_university_info`, ensuring graceful handling of scraping failures.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The placeholder CSS selectors in `scrape_university_info` must be replaced with accurate selectors based on the actual structure of the target university websites to extract meaningful data.\n",
        "*   Further enhancements could involve implementing a mechanism to dynamically identify and adapt to potential changes in website structures to maintain scraping functionality over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95ffb5c9"
      },
      "source": [
        "# Task\n",
        "Extract the list of all program names from the \"https://www.ouinfo.ca/programs/all\" page using the container selector \"div.results.results-programs\" and the program title selector \"h2.result-heading\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba27644a"
      },
      "source": [
        "## Create a function to list programs\n",
        "\n",
        "### Subtask:\n",
        "Develop a function that takes the `/programs/all` URL as input, fetches the content, and extracts a list of program names using the provided container selector and identifying the individual program name selectors within that container.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33a0aef1"
      },
      "source": [
        "**Reasoning**:\n",
        "Define a function `list_all_programs` to scrape program names from the provided URL using requests and BeautifulSoup, implementing the specified steps and error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788ca254"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def list_all_programs(url):\n",
        "  \"\"\"\n",
        "  Scrapes and lists all program names from the given URL.\n",
        "\n",
        "  Args:\n",
        "    url: The URL of the page listing all programs.\n",
        "\n",
        "  Returns:\n",
        "    A list of program names, or None if scraping fails or no programs are found.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    response = requests.get(url, timeout=10)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    programs_list = []\n",
        "\n",
        "    # Find the main container\n",
        "    container = soup.select_one('div.results.results-programs')\n",
        "\n",
        "    if not container:\n",
        "      print(f\"Could not find the main programs container on {url}\")\n",
        "      return None\n",
        "\n",
        "    # Find all program title elements within the container\n",
        "    program_elements = container.select('h2.result-heading')\n",
        "\n",
        "    if not program_elements:\n",
        "      print(f\"No program title elements found within the container on {url}\")\n",
        "      return None\n",
        "\n",
        "    # Extract program names\n",
        "    for program_element in program_elements:\n",
        "      programs_list.append(program_element.get_text(strip=True))\n",
        "\n",
        "    if programs_list:\n",
        "      return programs_list\n",
        "    else:\n",
        "      print(f\"No program names extracted from {url}\")\n",
        "      return None\n",
        "\n",
        "  except requests.exceptions.Timeout:\n",
        "    print(f\"Request timed out for URL: {url}\")\n",
        "    return None\n",
        "  except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching URL {url}: {e}\")\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred during scraping or parsing {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Example usage (will execute in the next step)\n",
        "# programs = list_all_programs(\"https://www.ouinfo.ca/programs/all\")\n",
        "# if programs:\n",
        "#     print(programs)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6a03764"
      },
      "source": [
        "**Reasoning**:\n",
        "Test the `list_all_programs` function with the specified URL to ensure it correctly extracts the program names.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28d5e021",
        "outputId": "5405c752-e08f-4eb3-8d96-77c62643504c"
      },
      "source": [
        "programs = list_all_programs(\"https://www.ouinfo.ca/programs/all\")\n",
        "if programs:\n",
        "    print(programs)\n",
        "else:\n",
        "    print(\"Failed to retrieve program list.\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Accounting', 'Accounting', 'Accounting', 'Accounting & Economics (BA) - Co-op', 'Accounting & Finance (Honours)', 'Accounting & Finance Co-op (Honours)', 'Accounting (BA 3 year)', 'Accounting (Co-op)', 'Accounting and Financial Management (Co-op Only)', 'Acounting & Economics', 'Acting (3 years)', 'Actuarial Science', 'Actuarial Science (BA)', 'Advertising', 'Aerospace Engineering (Co-op Available)', 'African Studies (BA - Co-op available)', 'Alternative Dispute Resolution', 'Alternative Dispute Resolution (Co-op)', 'Ancient Greek and Roman Studies', 'Ancient Greek and Roman Studies (Honours Arts) – Co-op', 'Ancient Greek and Roman Studies and Business', 'Animal Biology', 'Anishinaabe Studies (BA 3 year)', 'Anishinaabemowin (BA 3 year)', 'Anthropology  & Psychology', 'Anthropology & Business Administration', 'Anthropology & English Literature', 'Anthropology & Forensics (BA)', 'Anthropology & Forensics (BSc)', 'Anthropology & Media Studies', 'Anthropology & Sociology', 'Anthropology (4 years) (French Immersion Stream is available)', 'Anthropology (BA)', 'Anthropology (BA)', 'Anthropology (BA) - Co-Op', 'Anthropology (BA, iBA - Co-op available)', 'Anthropology (BSc)', 'Anthropology (BSc)', 'Anthropology (BSc) - Co-Op', 'Anthropology (Thunder Bay and Orillia)', 'Anthropology and Sociology (Joint Honours 4 years) (French Immersion Stream is available)', 'Applied Biotechnology', 'Applied Biotechnology (Co-op)', 'Applied Grape and Wine Science', 'Applied Health Sciences (BASc)', 'Applied Human Nutrition', 'Applied Life Sciences (Thunder Bay and Orillia)', 'Applied Linguistics', 'Applied Mathematics (BA)', 'Applied Mathematics (BSc)', 'Archaeology (BA)', 'Archaeology (BA) - Co-Op', 'Archaeology (BSc)', 'Archaeology (BSc) - Co-Op', 'Archaeology (Honours Arts) - Bioarchaeology', 'Architectural Engineering (Co-op only)', 'Architectural Science (Honours) (Co-op Available)', 'Architectural Studies', 'Architectural Studies', 'Architectural Studies (regular and co-op) – Architecture', 'Architecture (Co-op Only)', 'Art History (4-year major) (French Immersion Stream is available)', 'Artificial Intelligence (Honours Arts)', 'Artificial Intelligence (Honours Science)', 'Arts', 'Arts', 'Arts', 'Arts Degree (BA) + Master of Business Administration (MBA) with Co-op', 'Arts Degree (BA) + Master of Business Administration (MBA) with Co-op (Pending Senate Approval)', \"Arts Degree (BA) + Master's Degree (MA or MSc), Cardiff University\", 'Arts Degree (BA) + Master’s Degree (MA or MAP or MIPP)', 'Arts General', 'Arts Honours', 'Arts Honours, Psychology (Co-op option available)', 'Arts Leadership', 'Arts One (Thunder Bay)', 'Arts and Business', 'Arts and Contemporary Studies (Honours)', 'Arts and Humanities', 'Arts and Science I', 'Arts and Sciences', 'Arts – Interdisciplinary Studies (3 years)', 'Arts – Interdisciplinary Studies (4 years)', 'Arts, Honours (BA): St. Jerome’s University', 'Astrophysics', 'Astrophysics (Co-op)', 'Automation Systems Engineering Technology (Bachelor of Technology)', 'Automotive & Vehicle Engineering Technology I (Bachelor of Technology)', 'Automotive Engineering', 'Automotive Engineering (Co-op)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1f0922"
      },
      "source": [
        "## Create a function to list programs\n",
        "\n",
        "### Subtask:\n",
        "Develop a function that takes the `/programs/all` URL as input, fetches the content, and extracts a list of program names using the provided container selector and identifying the individual program name selectors within that container."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "591f75b0"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The process successfully extracted a list of program names from the specified URL \"https://www.ouinfo.ca/programs/all\" using the container selector `div.results.results-programs` and the program title selector `h2.result-heading`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The developed function `list_all_programs` can be reused to extract program names from similar pages on the same website if the HTML structure and selectors remain consistent.\n",
        "*   The extracted list of program names can be further analyzed (e.g., counting the total number of programs, identifying programs containing specific keywords) or used for other purposes.\n"
      ]
    }
  ]
}